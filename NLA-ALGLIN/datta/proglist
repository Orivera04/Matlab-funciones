
      C H A P T E R         T H R E E 


 BACKSUB Back substitution 
 y = backsub(T,b) computes the solution y of a nonsingular upper
 triangular system Ty = b using back substitution process.
 This program implements Algorithm 3.1.3 of the book.  
 Input  : Matrix T and vector b
 output : vector y


  C H A P T E R    F O U R


 GAUSS	Linear system solution using Gaussian elimination with economy in storage 
 x = gauss(A,b) computes the solution x of the linear
 system Ax = b using Gaussian Elimination.  The upper triangular
 part of A is overwritten by the triangular matrix produced at the end of the 
 (n-1)th step and the multipliers are stored in the lower triangular part of A. 
 On output b contains the final transformed vector.  
 This program calls the MATCOM program BACKSUB.
 This program implements Algorithm 4.2.3 of the book.
 input  : Matrix A and vector b 
 output : vector x


 HOUSMULP Post Multiplication By a Householder Matrix
 A = housmulp(A,u) computes the post-multiplication of
 a matrix A by the Householder matrix H generated by a 
 vector u.  The output matrix A contains the product AH.
 See Section 5.4 of the book.
 input  : Matrix A and vector u
 output : Matrix A


 INVUPTR Inverse of an upper triangular matrix 
 T = invuptr(T) computes the inverse of a nonsingular upper triangular
 matrix T.  The output matrix T contains the inverse of T. 
 This program implements Algorithm 4.2.2 of the book.
 Input  : Matrix T 
 output : Matrix T


 PHOUSMUL Pre Multiplication By Householder Matrix
 A = phousmul(A,u) computes the pre-multiplication
 of a matrix A by the Householder matrix generated
 by the vector u. The output matrix A contains the product HA. 
 This program implements Algorithm 4.2.1 of the book. 
 input   : Matrix A and vector u
 output  : Matrix A 


  C H A P T E R    F I V E 


 GIVQR	QR factorization by Givens rotation 
 [Q,R] = givqr(A) produces  an orthogonal matrix Q
 and a matrix R of the same size as A 
 with zeros below the diagonal, such that A = QR,
 using Givens rotations.
 This program calls MATCOM program GIVZERO.
 This program implements Algorithm 5.5.4 of the book and
 also explicitly computes Q and R.
 input  : Matrix A
 output : Matrices Q and R 


 GIVZERO Givens zeroing in a vector x.
 [c,s] = givzero(x) produces the Givens parameters c and s
 for a 2-vector x such that J(1,2,theta)x has a zero 
 in the second place. c = cos(theta), s = sin(theta).
 This program implements Algorithm 5.5.1 of the book.
 input   : Vector x 
 output  : Scalars c and s 


 HOUSQRN Householder QR factorization of a nonsquare matrix  
 [Q,R,A,v] = housqrn(A) produces an orthogonal matrix Q
 and an upper triangular matrix R of the same size as 
 A with zeros below the diagonal, so that A = QR, using
 Householder matrices.  The upper triangular part of
 the output matrix A contains R, and the lower triangular part
 contains the components u_k+1,k through u_nk of the
 vectors u_n-k=1 = (u_kk, .... u_nk)'.  The output vector v
 contains first components u_kk of the vector u_n-k+1.  
 This program calls MATCOM programs HOUSZERO and HOUSMULP.
 see Section 5.4.2 of the book.
 input   : Matrix A
 output  : Matrices Q, R, A and vector v   


 PARPIV Triangularization using Gaussian Elimination with partial pivoting
 [A,U,M] = parpiv(A) produces an upper triangular matrix U 
 and a permuted lower triangular matrix M using
 partial pivoting, so that MA = U. The lower triangular part
 of the output matrix A contains the multiplers and the upper triangular part  
 contains U. 
 This program implements Algorithm 5.2.2 of the book. 
 input  : Matrix A
 output : Matrices A, U and M 


 COMPIV	Triangularization using Gaussian elimination with complete pivoting 
 [A,U,M,Q] = compiv(A) produces an upper triangular matrix U,
 a permuted lower triangular matrix M,  and a permutation matrix Q,
 using complete pivoting so that MAQ = U.  The lower triangular part
 of the output matrix A contains the multipliers and the upper
 triangular part of A contains U.
 This program implements Algorithm 5.2.3 of the book.
 input  : Matrix A
 output : Matrices A, U, M and Q.  


 GIVROT	Givens rotation matrix from Givens paramters c and s.
 J = givrot(i,j,c,s,n) forms the n x n Givens rotation matrix J
 from the Givens paramters c and s.  A(i,i) = c, A(i,j) = s,
 A(j,i) = -s, A(j,j) = c.  The other entries of J are the
 same as those of an n x n Identity matrix.
 input  : Integers i, j, n and scalars c and s 
 output : Matrix J


 HOUSHESS Householder Hessenberg reduction 
 [H,P,A,v] = houshess(A) produces an upper Hessenberg matrix H from A
 using the Householder method such that H is orthogonally similar to A.
 PAP' = H.          
 The upper Hessenberg part of the output matrix A
 contains the upper Hessenberg matrix H, and the lower Hessenberg
 part contains the components u_k+2,k, through u_n,k of the
 vectors u_n-k = (u_k+1,k, ..., u_n,k)', k = 1, ... n-2.
 The output vector v contains the first components
 u_k+1,k of the vector u_n-k.  This program calls 
 the MATCOM programs HOUSZERO and HOUSMULP.
 This program implements Algorithm 5.4.4 of the book. 
 The matrix P is also explicitly formed.  
 input  : Matrix A
 output : Matrices H, P, A and vector v


 HOUSZERO Zeros in a vector using a Householder matrix. 
 [u,sigma] = houszero(x)  produces a vector u
 defining a Householder matrix H, and a scalar sigma
 such that Hx = [sigma, 0, ...., 0]'. 
 This program implements Algorithm 5.4.1 of the book.
 input  :  vector x
 output :  vector u, and scalar sigma


 PGIVMUL Premultiplication  by a Givens Matrix.
 A = pgivmul(A,i,j,c,s)  computes the premultiplication
 of the matrix A by the Givens matrix, J(i,j,theta), where
 1 <= i <=j <= m, and c = cos(theta), s = sin(theta).
 The output matrix A contains the product JA.
 This program implements Algorithm 5.5.2 of the book.
 Input   : Matrix A, Givens parameters c and s, indices i and j
 Output  : Matrix A


 GIVHS	Givens Hessenberg reduction 
 [H,P] = givhess(A) produces an upper Hessenberg matrix H
 and an orthogonal matrix P using the Givens
 method so that H is orthogonally similar to A.  PAP' = H.
 P is the product of (n-i+1) Givens rotations.
 This program implements Algorithm 5.5.4 of the book.
 input  : Matrix A
 output : Matrices H and P 


 GIVSZERO Givens specific zeroing in a vector.
 A = givszero(i,j,A) creates a zero in the (j,i)th position of a 
 matrix A using Givens rotation matrix J. The output matrix A 
 contains the product JA such that its (j,i)th entry is
 zero.  This program calls the MATCOM program PGIVMUL and 
 GIVZERO.
 This program implements Algorithm 5.5.3 of the book.
 input   : Integers i, j and Matrix A
 output  : Matrix A


 HOUSQR Householder QR factorization 
 [Q,R,A,v] = housqr(A) produces an orthogonal matrix Q
 and an upper triangular matrix R so that A = QR, using
 Householder matrices.  The upper triangular part of
 the output matrix A contains R, and the lower triangular part
 contains the components u_k+1,k through u_nk of the
 vectors u_n-k=1 = (u_kk, .... u_nk)'.  The output vector v
 contains first components u_kk of the vector u_n-k+1.  
 This program calls MATCOM programs HOUSZERO and HOUSMULP.
 This program implements Algorithm 5.4.3 of the book.
 input  : A square matrix A
 output : Matrices Q, R, A and vector v


 LUGSEL LU factorization using Gaussian elimination without pivoting 
 [A,L,U] = lugsel(A) produces the LU factorization of a matrix A using 
 Gaussian elimination without pivoting : A = LU.  L is unit lower triangular
 and U is upper triangular.  This program implements
 Algorithm 5.2.1 of the book. The matrices L and U are
  also explicitly  formed. The upper triangular part of the
 matrix A contains the matrix U and the lower triangular
 part of the matrix A contains the multipliers.
 input  : Matrix A
 output : Matrices A, L and U 


  C H A P T E R     S I X


 FORELM  Forward elimination
 y = forelm(L,b) computes the solution y of a nonsingular lower
 triangular system Ly = b using forward elimination process.
 This program implements Algorithm 6.4.1 of the book.
 Input  : Matrix L and vector b
 output : vector y 


 HAGCOND1 Hager's norm-1 condition number estimator
 [CND,ITER] = hagcond1(A) produces CND, the norm-1 condition number estimate
 using Hager's Algorithm. Integer iter is the number of
 iterations needed for the algorithm to converge.   
 This program calls the MATCOM programs BACKSUB and PARPIV.
 The program implements Algorithm 6.7.1 of the book.
 input  : Matrix A
 output : Scalar cnd and integer iter


 INCOMPIV Inverse by complete pivoting 
 T = incompiv(A) computes the inverse of a matrix A using complete
 pivoting : inv(A) = Q*inv(U)*M.  
 input  : Matrix A
 output : Matrix T


 ITERREF Iterative refinement 
 [x,iter] = iterref(A,b,x0,ep,numitr) iteratively computes succesive refinements
 of an initial solution x0 of the system Ax = b.  ep is
 the tolerance.  numitr is the user supplied number of iterations.
 If the process converged to the desired accuracy,  iter contains
 the iteration number needed to converge. 
 If the process did not converge, iter contains numitr.
 This program implements Algorithm 6.9.1 of the book.
 input  : Matrix A, vectors b and x0, scalar ep and integer numitr
 output : vector x and integer iter


 SHERMOR  Sherman Morrison formula 
 H = shermor(A,u,v) computes the inverse of a matrix obtained
 by rank-one change in a matrix A, using the Sherman-Morrison
 formula : inv(A - uv').  u and v are column vectors.
 see section 6.5.2 of the book
 input  : Matrix A and vectors u and v
 output : Matrix H


 CHOLES Cholesky factorization 
 [A,H] = choles(A) computes the Cholesky factorization of a
 symmetric positive matrix A : A = HH'. H is a lower triangular
 matrix with positive diagonal entries. On output, the lower 
 triangular part ofthe output matrix A contains H.  Note that MATLAB CHOL(A)
 produces an upper triangular matrix R such that R'*R = A. This
 program implements Algorithm 6.4.4 of the book.
 input  : Matrix A
 output : Matrices A and H


 GAUSED Gauss-Seidel method
 [x,iter] = gaused(A,x0,b,ep,numitr) computes the solution x of 
 the linear system Ax = b, using the Gauss-Seidel method.
 x0 is the initial approximation,  ep is the tolerance, numitr is the
 user supplied number of iterations.  If the Gauss-Seidel method
 converged, iter contains the number of iterations needed to converge.
 If the Gauss-Seidel method did not converge, iter contains numitr.
 This program implements Algorithm 6.10.2 of the book.
 input  : Matrix A, vectors x0 and b, scalar ep, and integer numitr 
 output : vector x and integer iter


 ICHOLES Incomplete Cholesky factorization 
 [A,L] = icholes(A) produces the incomplete Cholesky factor A of
  a sparse symmetric positive definite matrix A.  The program implements
  Algorithm 6.10.6 of the book.
 input  : Matrix A
 output : Matrices A and L


 INLU	Inverse using the LU factorization 
 T = inlu(A) computes the inverse T of A using LU factorization
 obtained by Gaussian elimination without pivoting.  
 input  : Matrix A
 output : Matrix T


 JACOBI Jacobi method 
 [x,iter] = jacobi(A,x0,b,ep,numitr) computes the solution x of Ax = b using
 the jacobi iterative method.  ep is the tolerance.  numitr is the 
 user supplied number of iteration.  x0 is the initial 
 approximate to the solution. 
 If the Jacobi method converged, iter contains the iteration number
 needed to converge.
 If the Jacobi method did not converge, iter contains numitr.
 This program implements Algorithm 6.10.1 of the book.
 input  : Matrix A and vectors x0 and b, scalar ep and integer numitr
 output : vector x and integer iter


 SUCOV Successive overrelaxation
 [x,iter] = sucov(A,x0,b,w,ep,numitr) computes the solution x
 of the linear system Ax = b using the successive
 overrelaxation iterative method.  x0 is the initial
 solution, numitr is the number of iterations to be performed,
 specified by the user and w is the relaxation
 parameter. (w > 1). If w = 1 then the successive
 overrelaxation iterative method reduces to the
 Gauss-Seidel iterative method. ep is the tolerance
 If the successive overrelaxation method converged,
 iter contains the iteration number needed to converge. If the successive
 overrelaxation method did not converge, iter contains
 numitr.
 This program implements Algorithm 6.10.3 of the book.
 input  : Matrix A, vectors x0 and b, scalars w and ep and integer numitr
 output : vector x and integer iter


 CONGRAD  Classical conjugate gradient method
 [x,iter] = congrad(A,x0,b,ep,numitr) computes the solution x 
 of a symmetric positive definite linear system Ax = b using
 the Conjugate Gradient method. 
 x0 is the initial approximation, ep is the tolerance,
 and numitr is the user supplied number of iterations.
 If the conjugate-gradient method converged, iter contains
 the iteration number needed to converge.  If the conjugate-gradient method
 did not converge, iter contains numitr.  
 This program implements Algorithm 6.10.4 of the book.
 input  : Matrix A, vectors x0 and b, scalar ep, and integer numitr
 output : Vector x, and integer iter.


 GAUSSWF  Linear system solution without explicit factorization
 x = gausswf(A,b) computes the solution x of the system Ax = b
 using Gaussian elimination with partial pivoting.  The factorization 
 MA = U is never explicitly formed. 
 The program calls the MATCOM program BACKSUB and INTER.
 The program implements Algorithm 6.4.2 of the book.
 input  : Matrix A and vector b
 output : vector x


 INCHOLES Inverse of a symmetric positive definite matrix using Cholesky factorization 
 T = incholes(A) computes the inverse of a symmetric positive 
 definite matrix A using its Cholesky factor H.
 inv(A) = inv(H')inv(H). 
 This program calls the MATCOM program CHOLES.
 See section 6.5.3 of the book.
 input  : Matrix A
 output : Matrix T


 INPARPIV Inverse by partial pivoting 
 T = inparpiv(A) computes the inverse T of a matrix A using Gaussian
 elimination with partial pivoting : inv(A) = inv(U) * M
 This program uses MATCOM program PARPIV.
 input  : Matrix A
 output : Matrix T


 NICHOL No-fill Incomplete LDL'. 
 [L,D] = nichol(A) computes the  no-fill incomplete Cholesky
 factorization of A, without any square roots :  A = LDL'. 
 This program implements Algorithm 6.10.7 of the book.
 input  : Matrix A
 output : Matrices L and D


  C H A P T E R    S E V E N


 LSFRMGS Least-squares solution by MGS.
 x = lsfrmgs(A,b) computes the least squares solution
 x of the full-rank overdetermined system Ax = b using modified
 Gram-Schmidt.
 This program calls the MATCOM programs BACKSUB and MDGRSCH. 
 This program implements Algorithm 7.8.5 of the book.
 input  : Matrix A and vector b
 output : vector x


 LSFRQRH Least Squares solutions using Householder QR
 x = lsfrqrh(A,b) computes the least squares solution x  to the full
 rank overdetermined system Ax = b using the Householder-Golub method.
 This program calls the MATCOM programs BACKSUB, HOUSZERO and PHOUSMUL.
 This program implements Algorithm 7.8.2 of the book.
 input  : Matrix A and vector b
 output : vector x


 LSITRN2 Iterative refinement for least-squares solution.
 x =  lsitrn2(A,b,numitr) refines iteratively a computed least 
 squares solution x of Ax = b. numitr is the  user supplied 
 number of iterations.  This program implements Algorithm 7.10.2
 of the book.
 input  : Matrix A, vector b, and integer numitr
 output : vector x


 MDGRSCH Modified Gram-Schmidt for QR factorization 
 [Q,R] = mdgrsch(A) computes the QR factorization of an m x n matrix A
 using the modified Gram-Schmidt method : A = QR, R is n x n upper
 triangular and Q is m x n and has orthonormal columns.
 This program implements Algorithm 7.8.4 of the book.
 input   : Matrix A
 output  : Matrices Q and R


 MNUDQRH Minimum-norm solution  for the underdetermined problem using QR  
 x = mnudqrh(A,b) computes the minimum norm solution x to the full rank
 underdetermined system Ax = b using the Householder QR factorization of A
 This program implements Algortihm 7.9.2 of the book.
 input  : Matrix A and vector b
 output : vector x


 CLGRSCH Classical Gram-Schmidt for QR factorization
 [Q,R] = clgrsch(A) computes the QR factorization
 of an m x n  matrix A using the classical Gram-Schmidt method : 
 A = QR, R is n x n upper triangular, Q is m x n and has orthonormal columns. 
 This program implements Algorithm 7.8.3 of the book.
 input   : Matrix A
 output  : Matrices Q and R


 LSFRNME Least-squares solution using normal equations 
 x = lsfrnme(A,b) computes the least squares solution x to the 
 full-rank overdetermined system Ax = b using the
 Normal equations. 
 This program calls the MATCOM programs CHOLES, FORELM and
 BACKSUB.
 This program implements Algorithm 7.8.1 of the book.
 input  : Matrix A and vector b
 output : vector x


 LSITRN1 Linear system analog least-squares iterative refinement. 
 x =  lsitrn1(A,b,numitr) refines iteratively a computed least 
 squares solution of Ax = b. numitr is the  user supplied 
 number of iterations.
 This is the linear system analog iterative refinement
 for a least squares solution.  For another iterative
 refinement algorithm see LSITRN2.
 This program calls the MATCOM program LSFRQRH. 
 This program implements Algorithm 7.10.1
 of the book.
 input  : Matrix A, vector b, and integer numitr
 output : vector x


 LSRDQRH Least-squares solutions for the rank deficient problem using Householder QR
 x = lsrdqrh(A,b) computes a minimum-norm least-squares solution x
 to the rank - deficient overdetermined system Ax = b using
 Householder QR Factorization A.  
 This program calls the MATCOM program BACKSUB.
 This program implements Algorthim 7.8.6 of the book. 
 input  : Matrix A and vector b
 output : vector x


 MNUDNME Minimum-norm solution for the underdetermined system using normal equations  
 x =  mnudnme(A,b) computes the minimum norm solution x to the full
 rank underdetermined system Ax = b using normal equations.  This
 program implements Algorthim 7.9.1 of the book.
 input  : Matrix A and vector b
 output : vector x


 VARCOVAR Variance-Covariance matrix 
 X = varcovar(A) computes the variance-covariance matrix X from A :
 X = inv(A' * A) explicitly without computing A'A. 
 This program implements Algorithm 7.11.1 of the book.
 input  : Matrix A
 output : matrix X


  C H A P T E R    E I G H T 


 LANSYM  Symmetric Lanczos algorithm
  [V,T] = lansym(A,v1,k) computes a k x k symmteric tridiagonal matrix 
 T and an orthonormal matrix V using the Lanczos
 algorithm.  Matrix A is symmetric and v1 is a unit vector.  
 Integer k is the number of basis vectors v1,v2, ... 
 to be computed.  This program implements Algorithm 8.12.2
 of the book.
 Input  : Matrix A, vector v1 and integer k
 Output : matrices V and T


 QRITRB	Basic QR iteration
 Ak = qritrb(A,numitr) returns the matrix Ak after 'numitr' number
 of basic QR iterations. numitr is a user specified integer.
 See Section 8.9.1 of the book. 
 input  : Matrix A and integer numitr
 output : Matrix Ak


 QRITRDSI One iteration step  of the Implicit Double Shift QR Iteration 
 [NH,Q] = qritrdsi(H) returns an upper Hessenberg matrix NH,
 starting from a given upper Hessenberg matrix H, using
 one step of implicit double shift QR iteration.  Q is the
 transforming orthogonal matrix : Q'HQ = NH. 
 This program calls the MATCOM program HOUSZERO.
 The program implements Algorithm 8.9.1 of the book.
 input  : Matrix H
 output : Matrix NH and Q


 QRITRSSE Explicit single-shift QR iteration
 H = qritrsse(A,numitr) returns an upper Hessenberg matrix H, starting
 from an arbitrary matrix A, using single-shift explicit QR iteration.
 numitr is the user-supplied number of iterations.  See Section 8.9.4 of
 the book.
 input  : Matrix A and integer numitr
 output : Matrix H


 SENSEIG Reciprocal of the condition numbers of eigenvalues 
 s = senseig(A) computes a vector s containing the reciprocals 
 of the condition numbers of the eigenvalues of a diagonalizable matrix A.  
 See Section 8.7.2 of the book.  
 input  : Matrix A
 output : vector s


 INVITR Inverse iteration
 [x,iter] = invitr(A,x0, sigma, ep,  numitr) computes an approximation x, of the
 eigenvector corresponding to a given approximation sigma of an eigenvalue,
 using inverse iteration.  x0 is the initial approximation,
 ep is the tolerance and numitr is the maximum number of iterations.  
 If the iteration converged, iter is the number of iterations
 needed to converge.  If the iteration did not converge,
 iter contains numitr. 
 This program implements Algorithm 8.5.2 of the book.
 input  : Matrix A, vector x0, scalars sigma, ep and integer numitr
 output : vector x and integer iter


 POWER	Power method 
 [lambda1,x,iter] = power(A,x0,ep,numitr) computes the dominant
 eigenvalue lambda1 and the corresponding eigenvector using the
 power method.  x0 is the initial vector, ep is the
 tolerance and numitr is the
 maximum number of iterations.  On output, if the power method converged,
 iter contains the iteration number needed to converge.
 If the power method did not converge, iter contains  the value of numitr.
 This program implements Algorithm 8.5.1 of the book.
 input  : Matrix A, vector x0, scalar ep and integer numitr
 output : Scalar lambda1, vector x, and integer iter


 QRITRDSE Explicit double shift QR iteration 
 NH = qritrdse(H,numitr) returns an upper Hessenberg matrix NH, starting from 
 a given upper Hessenberg matrix H, using explicit double-shift QR
 iteration.  numitr is the number of iterations specified by the user.
 see section 8.9.5 of the book.  The matrix H is overwritten by
 itself after each iteration.
 input  : Matrix H and integer numitr
 output : matrix NH


 QRITRH Hessenberg-QR iteration 
 A = qritrh(A,numitr) returns a reduced Hessenberg matrix starting 
 from a given upper Hessenberg matrix A using QR iterations.
 Givens rotations are used to factor A(k) into Q(k)R(k) .
 numitr is the user supplied number of iterations. 
 See Section 8.9.2 of the book.
 input  : Matrix A and integer numitr
 output : Matrix A


 RAYQOT Rayleigh quotient iteration 
 [sigma,x,iter] = rayqot(A,x0,ep,numitr) computes an approximate          
 eigenpair(sigma,x) of a matrix A using Rayleigh-Quotient iteration.
 x0 is the initial approximation to the eigen vector x.  ep is the tolerance
 numitr is the user-supplied number of iteration.  On output, if the
 Rayleigh quotient iteration converged, iter contains the iteration number
 needed to converge. If the iteration did not converge, iter contains
 the value of numitr.
 This program implements Algorithm 8.5.3 of the book.  
 input  : Matrix A, vector x0, scalar ep and integer numitr
 output : Scalar sigma, vector x and integer iter


      C H A P T E R       N I N E 


 GENRAYQT Generalized Rayleigh quotient iteration
 [lamda,x,iter] = genrayqt(A,B,x0,ep,numitr) computes approximations to
 the eigenvectors and the eigenvalues of the symmetric definite
 pencil A - lambda B.  A is symmetric and B is positive definite.  
 x0 is chosen such that norm(x0) = 1. numitr is the user
 supplied number of iterations. ep is the tolerance.
 If the method converged, iter contains the number of iterations
 needed to converge.  If the method did not converge iter 
 contains the value of numitr.
 This program implements Algorithm 9.5.4 of the book.
 input  : Matrices A and B, vector x0, scalar ep and integer numitr
 output : Scalar lamda, vector x and integer iter.


 HESSTRI Hessenberg-Triangular Reduction
  [A,B] = hesstri(A,B) overwrites
 A with and upper hessenberg matrix by orthogonal transformations
 and B with an upper triangular matrix by orthogonal transformations.
 see Section 9.3.1 of the book
 input  : Matrices A and B
 output : Matrices A and B


 LANSYMGN  Lanczos Algorithm for Symmetric Definite Pencil
 [V,T] = lansymgn(A,B,v1,j) constructs a symmetric tridiagonal matrix T 
 and an orthonormal matrix Vj = [v1,v2, ..., vj] such that
 Vj'AVj = Tj and Vj'BVj = I(jxj).  
 Matrices A and B are symmetric and B is positive definite.
 This program implements Algorithm 9.9.1 of the book.
 input  : Matrices A and B, vector v1, and integer j.
 output : Matrices V and T


 QUADEIG2 Quadratic Eigenvalue Problem via Reduction to a Generalized Eigenvalue Problem 
 [V,lam] = quadeig2(M,D,K)  computes the eigenvalues and
 eigenvectors of the quadratic eigenvalue problem via 
 reduction to a generalized eigenvalue problem.
 The vector lam contains the eigenvalues and the
 matrix V contains the corresponding eigenvectors.
 See Section 9.8 of the book. 
 input  : Matrices M,D and K
 output : Matrix V and vector lam


 CHOLQR  Cholesky-QR algorithm for the symmetric definite pencil
 [X,lam] = cholqr(A,B) computes the eigenvalues and  eigenvectors for the
 symmetric definite pencil (A - lambda B). Matrix X contains the eigenvectors 
  and the vector lam contains the eigenvalues. 
 A is symmetric and B is symmetric positive definite.
 This program calls the MATCOM program BACKSUB.
 This program implements Algorithm 9.5.1 of the book.
 input  : Matrices A and B
 output : Matrix X, and vector lam.


 GENSTURM Sturm sequence method
  r = gensturm(A,B)
 Given A and B n x n matrices, the algorithm computes
 the eigenvalues of the symmetric definite tridiagonal
 pencil (A - lambda B) by computing the zeros of Pn(lamda).
 Matrices A and B are both symmetric tridiagonal
 and B is positive definite.  See Section 9.9.1 of the book.
 input  : Matrices A and B
 output : Vector r 


 INVITRGN Eigenvectors.
 [v,iter] = invitrgn(A,B,v0,lambda,numitr) computes the  
 eigenvector v corresponding to an eigenvalue lambda of
 the generalized eigenvalue problem A - lambda B, by
 inverse iteeration.
 v0 is the initial eigenvector.
 numitr is the user supplied number of iterations.
 If the method did not converge, iter contains the value of numitr.
 This program implements Algorithm 9.4.1 of the book.
 input  : Matrices A and B, vector v0, scalars lambda  and integer numitr
 output : vector v, integer iter


 QUADEIG1 Quadratic Eigenvalue Problem via Standard Reduction 
 [V,lam] = quadeig1(M,D,K)  computes the eigenvalues and
 eigenvectors of the quadratic eigenvalue problem via 
 the reduction to a standard eigenvalue problem.
 The vector lam contains the eigenvalues and 
 matrix V the corresponding eigenvectors.
 See Section 9.8 of the book. 
 input  : Matrices M,D and K
 output : Matrix V and vector lam


 SIMDIAG Simultaneous diagonalization of a symmetric definite pencil
 X = simdiag(A,B) computes a nonsingular matrix X such that 
 X'BX is the identity matrix and X'AX is a diagonal matrix.
 Matrices A and B are symmetric and B is positive definite.
 This program implements Algorithm 9.5.3 of the book.
 input  : Matrices A and B
 output : Matrix X


      C H A P T E R         T E N 


 BIDIAG  Reduction to bidiagonal form.
 B = bidiag(A)  reduces the matrix A to bidiagonal form. 
 This program calls the MATCOM programs HOUSZERO and PHOUSMUL.
 See Section 10.9 of the book.
 input  : Matrix A
 output : Matrix A


 COVSVD  Variance-Covariance matrix
 C = covsvd(A) computes the variance covariance matrix 
 inv(A'*A) using the SVD of A.   
  see section 10.7 of the book.
 input  : Matrix A
 output : Matrix C


 LSQRSVD Least-squares solutions using the SVD
 x = lsqrsvd(A,b) computes the least squares solution x using the
 the SVD of A.
 This program implements Algorithm 10.8.1 of the book.
 input  : Matrix A and vector b 
 output : vector x


 MINNMSVD Minimum norm least-squares solution using the SVD
 x = minnmsvd(A,b) computes the minimum norm least squares 
 solution x using the SVD of A.
 This program implements Algorithm 10.8.1 of the book to 
 compute the minimum-norm least-squares solution.
 input  : Matrix A and vector b 
 output : vector x


 ORTHPROJ Orthogonal projections using the SVD.
 [R,N,OR,ON]  = orthproj(A) computes the orthogonal projections
 once the orthonormal bases for the range R(A) and the null-space
 N(A) of A are obtained, using the SVD of a : [ U, S, V] = SVD(A).
 R is the projection onto R(A) = U1 * U1'
 N is the projection onto N(A) = V2 * V2'
 OR is the projection onto the orthogonal complement of R(A) = U2 * U2'
 ON is the projection onto the orthogonal complement of N(A) = V1 * V1'
 see section 10.6.2 of the book
 input  : Matrix A
 output : Matrices R, N, OR and ON


    N O            C H A P T E R 


 ABSMAX  The position p in a vector where the absolute maximum occurs.
 p = absmax(y) returns the postion p in the vector y
 where the absolute maximum of the vector y occurs.
 input  : Vector y
 output : Integer p


 CPUTIME CPU time in seconds.
 	CPUTIME returns the CPU time in seconds that has been used
 	by the MATLAB process since MATLAB started.  
 
 	For example:
 
  	    t=cputime; your_operation; cputime-t
 
 	returns the cpu time used to run your_operation.	    
  
 	The return value may overflow the internal representation
 	and wrap around.
 
 	See also ETIME, TIC, TOC, CLOCK


 INTER	 Interchange two vectors 
 [y,z] = inter(y,z) interchanges two vectors y and z
 so that on output y contains z and z contains y.
 input  : Vectors y and z
 output : Vectors y and z

